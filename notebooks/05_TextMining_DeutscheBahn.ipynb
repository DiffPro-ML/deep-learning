{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stimmungsanalyse mit dem DB-Social-Media Datensatz\n",
    "\n",
    "Der Datensatz wurde zur Stimmungsanalyse und Erkennung von relevanten Feedback erstellt.\n",
    "Weitere Dokumentation und Downloads sind unter https://sites.google.com/view/germeval2017-absa/data?authuser=0 zu finden.\n",
    "\n",
    "\n",
    "Der Datensatz wird mittels Logistischer Regression, FastText und Bert bearbeitet.\n",
    "# Jupyter-Notebook\n",
    "\n",
    "Jupyter-Notebooks sind interaktive Python-Scripte, in denen Markdown und sogar Latex zur Dokumentation verwendet werden kann. In diesem Abschnitt sollen einerseits allgemeine Informationen wie Tastenkombinationen und übliche Workflows, andererseits aber auch für diesen Workshop und die verwendete Hardware spezifische Informationen im Umgang mit Python und Jupyter-Notebooks geliefert werden.\n",
    "\n",
    "### Wichtiges auf einen Blick (a.k.a. TL;DR)\n",
    "\n",
    "- **beim Wechseln auf ein anderes Notebook immer den Kernel beenden (Kernel -> Shutdown)**\n",
    "- **Shift + Enter** zum Ausführen der aktiven Zelle\n",
    "- **Strg + Shift + p** zum Öffnen der Kommandopalette\n",
    "- **Shift + o** zum Togglen des Zell-Scrollings\n",
    "- bei Fehlermeldungen im Zweifel **Kernel neustarten (Kernel -> Restart)**\n",
    "- \"Hilfe, ich sehe den Markdown-Code\" -> **Shift + Enter** in der entsprechenden Zelle\n",
    "- \"Hilfe, ich bekommen ResourceExhaustion / OutOfMemory (OOM) Fehler\" -> **Kernel neustarten, Kernel von anderen noch laufenden Notebooks herunterfahren** (oben links auf das Jupyter-Logo klicken, dann auf den Tab \"Running\")\n",
    "- \"Hilfe, mein Notebook ist kaputt\" -> siehe **Notebook \"Wiederherstellung\"**\n",
    "- \"Passiert da noch was?\" -> ist der **Kreis oben rechts neben \"Python 3\", ausgefüllt und dunkel** dann ist der Kernel noch am Arbeiten, ist er nicht gefüllt dann ist der Kernel untätig. Die aktuell laufende Zelle ist die von oben gesehen erste bei der auf der linken Seite \"In[*]\" anstelle von z.B. \"In[5]\" steht. Es kann aber passieren dass sich der Kernel aufhängt, in dem Fall einfach oben auf __Kernel -> Interrupt__ und die Zelle erneut ausführen\n",
    "\n",
    "\n",
    "### Überblick & Workflow\n",
    "\n",
    "Die einzigen beiden Shortcuts die man sich eigentlich nur merken muss sind\n",
    "\n",
    "- **Shift + Enter** zum Ausführen einer Zelle, und\n",
    "- **Strg + Shift + p** zum Öffnen der Kommandopalette, von der aus man dann direkt Zugriff auf alle möglichen Befehle hat, inklusive entsprechender Shortcuts\n",
    "\n",
    "Ein weiterer nützlicher Shortcut ist **Shift + o**, welcher das **Scrolling für Zellenoutput** umschaltet.\n",
    "\n",
    "Zum **Editieren einer Zelle** genügt ein Doppelklick in die Zelle, bei Code-Zellen reicht es zum Beenden des Editiermodus einfach außerhalb der Zelle zu klicken, bei Dokumentationszellen (wie dieser hier) ist eine Ausführung der Zelle nötig um die Code-Ansicht zu verlassen.\n",
    "\n",
    "Während eine Zelle ausgeführt wird, wechselt der Kernel-Indikator oben rechts neben \"Python 3\" von einem hellen Kreis mit dunklem Rand zu einem ausgefüllten dunklen Kreis und springt wieder zurück sobald die Ausführung beendet ist. Wenn mehrere Zellen gleichzeitig ausgeführt wurden, kann man an dem Label in der linken Spalte ablesen, ob die Zelle fertig ausgeführt wurde (**In [ZAHL]:**) oder ob sie gerade ausgeführt wird bzw. auf Ausführung wartet (**In [*]:**). Zusätzlich wird nach Ausführung einer Zelle die Zellenausgabe unterhalb der Zelle angezeigt.\n",
    "\n",
    "Um den Überblick zu behalten kann es manchmal sinnvoll sein, die **Zellenausgabe zu löschen**. Dies kann u.a. auf diesen beiden Wegen erfolgen:\n",
    "\n",
    "- oben auf Cell -> Current Outputs / All outputs -> Clear\n",
    "- oben auf Kernel -> Restart & Clear Output\n",
    "\n",
    "Der Kernel ist für die Ausführung des Python-Codes zuständig und behält den Kontext (also belegte Variablen, definierte Funktionen und belegter Speicher) seit dem letzten Kernel-(Neu)start. Dies kann zu Problemen führen wenn Zellen in anderer Reihenfolge ausgeführt werden oder Zellen übersprungen werden in denen Variablen oder Funktionen definiert werden die im weiteren Verlauf des Scripts benötigt werden, aber auch wenn **ein anderes Jupyter-Notebook gestartet wird**, da dafür ein weiterer Kernel gestartet wird.\n",
    "\n",
    "Deswegen beim **Wechseln auf ein anderes Notebook** immer den **Kernel herunterfahren oder neustarten** (oben Kernel -> Restart/Shutdown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import gensim\n",
    "import sys\n",
    "sys.path.insert(1, '/data/db_twitter/')\n",
    "import data_cleaner\n",
    "import fasttext\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "import random as rn\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from transformers import BertForSequenceClassification, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "import transformers as ppb\n",
    "import csv\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from apex import amp\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"/workspace\")\n",
    "DATA_DIR = os.path.abspath(\"/data\")\n",
    "\n",
    "TRAIN_DF=DATA_DIR+\"/db_twitter/train_v1.4.tsv\"\n",
    "TEST_DF=DATA_DIR+\"/db_twitter/dev_v1.4.tsv\"\n",
    "CLEAN_TRAIN_DF=DATA_DIR+\"/db_twitter/train_clean.tsv\"\n",
    "CLEAN_TEST_DF=DATA_DIR+\"/db_twitter/test_clean.tsv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datenanalyse\n",
    "Zur Analyse laden wir den Testdatensatz ein und schauen uns die erste Zeile an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_train = pd.read_csv(TRAIN_DF, delimiter='\\t', header=None )\n",
    "analyse_test = pd.read_csv(TEST_DF, delimiter='\\t', header=None )\n",
    "\n",
    "print(\"Trainingsmenge:\")\n",
    "print(analyse_train[:5])\n",
    "print(\"\\n\"+analyse_train[1].iloc[0])\n",
    "\n",
    "print(\"\\n\\nTestmenge:\")\n",
    "print(analyse_test[:2])\n",
    "print(\"\\n\"+analyse_test[1].iloc[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Klassenverteilung\n",
    "Die Verteilung der Klassen sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_train, counts_train = np.unique(analyse_train[3], return_counts=True)\n",
    "unique_test, counts_test = np.unique(analyse_test[3], return_counts=True)\n",
    "\n",
    "print(\"Trainingsmenge: \")\n",
    "print((np.asarray((unique_train, counts_train)).T))\n",
    "\n",
    "print(\"\\nTestmenge: \")\n",
    "print(np.asarray((unique_test, counts_test)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Daten bereinigen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für unsere Aufgabe benötigen wir nur den Text der Posts und die Labels, daher nutzen wir nur die Spalten 1 und 3.\n",
    "\n",
    "Um Erwähnungen zu vereinfachen, wird jeder Twitterusername durch den Text 'twitterusername' ersetzt. @DB_Bahn wird besonders gekennzeichnet, da er hier von besonderer Bedeutung ist.\n",
    "\n",
    "Zudem werden Satzzeichen entfernt und Emojis durch festgelegte Wörter ersetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(TRAIN_DF, delimiter='\\t', usecols=[1,3], header=None )\n",
    "test_data=pd.read_csv(TEST_DF, delimiter='\\t', usecols=[1,3], header=None )\n",
    "\n",
    "print(train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Datensätze werden bereinigt, dies kann einige Zeit in anspruch nehmen...\")\n",
    "clean_train_data=train_data.apply(data_cleaner.clean_text)\n",
    "clean_test_data=test_data.apply(data_cleaner.clean_text)\n",
    "print(\"Datensätze bereinigt.\")\n",
    "\n",
    "print(clean_train_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die bereinigten Datensätze sind bereits gespeichert und können im Folgenden geladen werden.\n",
    "Ein Vergleich der originalen und bereinigten Daten kann hier angesehen werden. Über das Argument in `.iloc[]`kann der Eintrag gewählt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"original: \",train_data[1].iloc[2])\n",
    "print(\"\\nbereinigt: \",clean_train_data[1].iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bereinigte Trainings und Testdaten laden\n",
    "**Wird verwendet, falls das Bereinigen übersprungen werden soll**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_data = pd.read_csv(CLEAN_TRAIN_DF, delimiter='\\t',header=None)\n",
    "clean_test_data = pd.read_csv(CLEAN_TEST_DF, delimiter='\\t',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistische-regression mit Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Trainings und Testdatensatz wird mit Gensim zum vectorisieren vorverarbeitet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(fname):\n",
    "    for i in range(0,fname.shape[0]):\n",
    "            tokens = gensim.utils.simple_preprocess(str(fname[0].iloc[i]))\n",
    "            yield gensim.models.doc2vec.TaggedDocument(tokens, str(fname[1].iloc[i]))\n",
    "                \n",
    "train_corpus = list(read_corpus(clean_train_data))\n",
    "test_corpus = list(read_corpus(clean_test_data))       \n",
    "\n",
    "print(\"Trainingsdaten:\")\n",
    "print(train_corpus[:1])\n",
    "print(\"\\nTestdaten:\")\n",
    "print(test_corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Modell erzeugen\n",
    "Gensim wird für ganze Sätze konfiguriert(docs) und das Wörterbuch wird erstellt. \"min_count\" ignoriert alle Wörter, die seltener als definiert vorkommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=2, epochs=15)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst werden Text und Labels für einfache Weiterverwendung extrahiert, danach werden die Trainingsdaten von dem Modell vorhergesagt und zwischengespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets, train_regressors = zip(*[(doc.words, doc.tags) for doc in train_corpus])\n",
    "test_targets, test_regressors = zip(*[(doc.words, doc.tags) for doc in test_corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(train_targets)):\n",
    "    X.append(model.infer_vector(train_targets[i]))\n",
    "train_x = np.asarray(X)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Logistische Regression\n",
    "Die erwarteten Labels werden an die Logistische regression gegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.asarray(train_regressors)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y)\n",
    "train_y = le.transform(Y)\n",
    "\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Genauigkeit der Testmenge\n",
    "Hier wird die Testmenge von dem Modell analysiert. Die Zusammenfassung wird von SKLearn angezeigt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "for i in range(len(test_targets)):\n",
    "    test_list.append(model.infer_vector(test_targets[i]))\n",
    "test_x = np.asarray(test_list)\n",
    "\n",
    "\n",
    "test_Y = np.asarray(test_regressors)\n",
    "test_y = le.transform(test_Y)\n",
    "\n",
    "preds = logreg.predict(test_x)\n",
    "\n",
    "print(classification_report(test_y,preds,target_names=[\"negative\",\"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 FastText\n",
    "\n",
    "[FastText](https://fasttext.cc/) ist ein Framework von Facebook zum Klassifizieren von Texten. Es ist effizient und kann sogar auf Mobilgeräten verwendet werden.\n",
    "\n",
    "\n",
    "## 4.1 Vorverarbeitung für FastText\n",
    "Zuerst werden die Kommentare mit Labels versehen. Sie werden aus dem Datensatz in diese Form gebracht: <br>\n",
    "\"\\__label\\__<positive/neutral/negative> >Kommentar<\".\n",
    "    \n",
    "Die ersten zwei Einträge werden angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addLabels(dataframe):\n",
    "    for i in range(0,dataframe.shape[0]):\n",
    "        yield \"__label__\"+str(dataframe[1].iloc[i])+\" \"+ str(dataframe[0].iloc[i])\n",
    "        \n",
    "        \n",
    "labeledList_train=list(addLabels(clean_train_data))\n",
    "labeledList_test=list(addLabels(clean_test_data))\n",
    "\n",
    "with open(ROOT_DIR+\"/fasttext_train.txt\",'w') as f:\n",
    "    for line in labeledList_train:\n",
    "        f.write(line+\"\\n\")\n",
    "\n",
    "with open(ROOT_DIR+\"/fasttext_test.txt\",'w') as f:\n",
    "    for line in labeledList_test:\n",
    "        f.write(line+\"\\n\")\n",
    "\n",
    "print(labeledList_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Training\n",
    "Anschließend wird mit FastText der Text trainiert. Die Anzahl der Epochen, Lernrate ([0.1,1]) und NGram-länge ([1,5]) kann angepasst werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=ROOT_DIR+\"/fasttext_train.txt\",epoch=20,lr=0.2,wordNgrams=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Test des Modells\n",
    "Um das Modell zu testen, wird der Testdatensatz übergeben.\n",
    "\n",
    "Die Ausgabe ist wie folgt Formatiert: (Samples, Precision, Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(ROOT_DIR+\"/fasttext_test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Einzelinferenz\n",
    "Hier können eigene Sätze mit dem Modell getestet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_predict=\"@DB_Bahn Heute mal wieder viel zu spät :(\"\n",
    "\n",
    "#preprocess input\n",
    "df=pd.DataFrame([to_predict])\n",
    "df=df.apply(data_cleaner.clean_text)\n",
    "to_predict=(df[0].item())\n",
    "\n",
    "print(\"'\",to_predict,\"'\")\n",
    "\n",
    "model.predict(to_predict, k=-1, threshold=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 5 Bert\n",
    "[Bert](https://huggingface.co/transformers/model_doc/bert.html) (Bidirectional Encoder Representations from Transformers) ist ein Modell, das nicht nur die Wörter in einem Text, sondern auch den Kontext analysiert.\n",
    "\n",
    "In diesem Notebook wird Pytorch als Backend verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_data = pd.read_csv(CLEAN_TRAIN_DF, delimiter='\\t',header=None)\n",
    "clean_test_data = pd.read_csv(CLEAN_TEST_DF, delimiter='\\t',header=None)\n",
    "print(clean_train_data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Preprocessing\n",
    "Das Modell erwartet die Labels als Ordinale, daher werden sie umgewandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toOrdinal(n):\n",
    "    if n=='positive':\n",
    "        return 2\n",
    "    if n=='neutral':\n",
    "        return 1\n",
    "    if n=='negative':\n",
    "        return 0\n",
    "        \n",
    "bert_train=pd.DataFrame({'label':clean_train_data[1].apply(toOrdinal),\n",
    "                         'text':clean_train_data[0]})\n",
    "\n",
    "bert_test=pd.DataFrame({'label':clean_test_data[1].apply(toOrdinal),\n",
    "                         'text':clean_test_data[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Text wird mit Hilfe von BERT in Tokens mit Start- und Stopp-Symbolen umgewandelt. Es werden nur Eingaben von 512 Zeichen unterstützt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-german-cased\", do_lower_case=True)\n",
    "print(\"Token werden erstellt, dies kann einige Zeit in anspruch nehmen..\")\n",
    "train_tokenized = bert_train['text'].astype(str).apply((lambda x: tokenizer.encode(x[:512], add_special_tokens=True)))\n",
    "test_tokenized = bert_test['text'].astype(str).apply((lambda x: tokenizer.encode(x[:512], add_special_tokens=True)))\n",
    "print(\"Token erstellt!\")\n",
    "\n",
    "print(\"\\nText:\",clean_train_data[0].iloc[0])\n",
    "print(\"\\nAls Token:\",train_tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Padding der Daten\n",
    "Da auf die Daten möglichst performant zugegriffen werden soll, werden sie als Arrays gespeichert. Die längste Zeichenkette gibt daher die größe der Arrays vor. Alle anderen werden am ende mit 0 aufgefült. Die `Attention Mask` filtert die aufgefüllten Werte später raus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in train_tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "        \n",
    "for i in test_tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)        \n",
    "\n",
    "            \n",
    "\n",
    "train_padded = np.array([i + [0]*(max_len-len(i)) for i in train_tokenized.values])\n",
    "train_attention_mask = np.where(train_padded != 0, 1, 0)\n",
    "\n",
    "test_padded = np.array([i + [0]*(max_len-len(i)) for i in test_tokenized.values])\n",
    "test_attention_mask = np.where(test_padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Daten für GPU vorbereiten\n",
    "Hier werden Datensätze zum Training und Testen erzeugt. Übergeben werden die Token-Sätze, Masken und Label. Die `Dataloader` laden die Datensätze mit der Größe `BATCH_SIZE` wenn benötigt auf die GPU, um den GPU-Speicher nicht durch den Datensatz auszulasten. In diesem Fall werden gleichzeitig 50 Einträge verarbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= TensorDataset(torch.tensor(train_padded),\n",
    "                             torch.tensor(train_attention_mask),\n",
    "                             torch.tensor(list(bert_train['label'])))\n",
    "\n",
    "test_dataset= TensorDataset(torch.tensor(test_padded),\n",
    "                            torch.tensor(test_attention_mask),\n",
    "                            torch.tensor(list(bert_test['label'])))\n",
    "\n",
    "BATCH_SIZE=50\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = BATCH_SIZE\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = BATCH_SIZE\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Modell erstellen\n",
    "Es wird ein BERT Modell mit 12 Layern erzeugt, die Anzahl an Labels muss mit dem Datensatz übereinstimmen (hier \"positive\", \"neutral\", \"negative\").\n",
    "\n",
    "Der \"cuda()\" Aufruf verschiebt das Modell auf die GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-german-cased\",\n",
    "    num_labels = 3,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Optimizer und Lernrate\n",
    "Als Optimizer verwenden wir Adam, da dieser sehr schnell konvergiert.\n",
    "Um möglichst viele Daten gleichzeitig zu verarbeiten, verwenden wir `half-precision`. Wenn möglich, werden Float16 anstelle von Float32 Werte verwendet, wodurch Ressourcen gespart werden. Die Level werden von [APEX](https://nvidia.github.io/apex/amp.html) definiert und können nachgeschlagen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(),\n",
    "                  lr = 0.000003, # args.learning_rate - default is 5e-5,\n",
    "                  eps = 0.0000001 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "model, optimizer = amp.initialize(model, optimizer,opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Training vorbereiten\n",
    "Die Anzahl an Epochen kann über `epochs` eingestellt werden. Die Lernrate wird über einen scheduler gesteuert.\n",
    "Die Funktionen dienen zur darstellung des Fortschritts im Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Training\n",
    "Das Training bestet aus dem Training mit der Trainingsmenge und Validierung mit der Validierungsmenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use cuda device\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "# same seed for reprodiction\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "\n",
    "training_stats = []\n",
    "\n",
    "# time measure\n",
    "total_t0 = time.time()\n",
    "\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    # ========================================\n",
    "    # Training\n",
    "    # ========================================\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    #training time for epoch\n",
    "    t0 = time.time()\n",
    "\n",
    "    # reset total loss\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # change model mode to training\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 20 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # elapsed time\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        #clear calculated gradiends\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # train model with current batch\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # training loss of all batches for statistics\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # calculate gradients\n",
    "        #loss.backward() ####changed for apex fp16\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "        \n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    # put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # constructing the compute graph is only needed for training\n",
    "        with torch.no_grad():        \n",
    "\n",
    "           \n",
    "            # the documentation for this model function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "            # values prior to applying an activation function like the softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # calculate the accuracy \n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Einzelinferenz\n",
    "Hier können eigene Sätze mit dem Modell getestet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict=\"@DB_Bahn heute wieder später\"\n",
    "\n",
    "def fromOrdinal(n):\n",
    "    if n==2:\n",
    "        return 'positiv'\n",
    "    if n==1:\n",
    "        return 'neutral'\n",
    "    if n==0:\n",
    "        return 'negativ'\n",
    "\n",
    "#preprocess input\n",
    "df=pd.DataFrame([to_predict])\n",
    "df=df.apply(data_cleaner.clean_text)\n",
    "to_predict=(df[0].item())\n",
    "\n",
    "print(\"Vorverarbeiteter Text: '\",to_predict,\"'\")\n",
    "\n",
    "tokenized=tokenizer.encode(to_predict[:512])\n",
    "print(\"\\nTokenized: \",tokenized)\n",
    "\n",
    "\n",
    "#predict input\n",
    "input_ids = torch.tensor([tokenized]).cuda()\n",
    "with torch.no_grad(): \n",
    "    model.eval()\n",
    "output=model(input_ids,token_type_ids=None)\n",
    "\n",
    "#parse output\n",
    "labels=[]\n",
    "for tensor in output[0][0]:\n",
    "    labels.append(tensor.item())\n",
    "\n",
    "predicted=fromOrdinal(np.argmax(labels))\n",
    "print(\"\\nErgebnis: \",predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
